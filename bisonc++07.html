<!DOCTYPE html><html><head>
<meta charset="UTF-8">
<title> <div style="text-align: center"><strong>Bisonc++</strong> (Version 4.10.01) User Guide</div> </title>
<style type="text/css">
    figure {text-align: center;}
    img {vertical-align: center;}
</style>
</head>
<body text="#27408B" bgcolor="#FFFAF0">
<hr>
<ul>
    <li> <a href="bisonc++.html">Table of Contents</a>
    <li> <a href="bisonc++06.html">Previous Chapter</a>
    <li> <a href="bisonc++08.html">Next Chapter</a>
</ul>
<hr>
<a name="ALGORITHM"></a><a name="l103"></a>
<h1>Chapter 7: The Bisonc++ Parser Algorithm</h1>
This chapter describes the algorithm that is used by <strong>bisonc++</strong>. Generating parsers
of course begins with a grammar to be analyzed. The analysis consists of
these steps:
    <ul>
    <li> First, a set of <code>FIRST</code> tokens is determined. The <code>FIRST</code> set of
a nonterminal defines all terminal tokens that can be encountered when
beginning to recognize that nonterminal.
    <li> Having determined the <code>FIRST</code> set, the grammar itself is
analyzed. Starting from the start rule all possible syntactically correct
derivations of the grammar are determined.
    <li> At each state actions are defined that are eventually used by the
parser to determine what to do in a particular state. These actions are based
on the next available token and may either involve a transition to another
state (called a <em>shift</em>, since it involves processing a token by `shifting'
over the next part of the input) or it may involve a reduction (a <em>reduce</em>
action), in which the parser stack's size is somewhat reduced. In the latter
case, if an <em>action</em> is associated with a particular rule, the action is
executed as a side effect of the reduction.
    <li> Sometimes the analysis takes the parser generator to a state in which
a choice between a <em>shift</em> or a <em>reduce</em> action must be made. This is
called a <em>shift-reduce</em> conflict. Sometimes the parser generator is able to
solve these conflicts itself, by looking at the next available token (the
<em>look-ahead</em> token). If the next token is not a possible continuation for
either a shift or a reduce action that particular continuation can be
discarded. Likewise, two reductions may be encountered in a state (a
<em>reduce-reduce</em> conflict). Here the same reasoning can be applied, maybe
resulting in discarding one of the possible reductions. In all other cases
(i.e., if the look-ahead token is possible for both continuations) a true
conflict is observed which somehow is solved by the grammar designer. If the
designer doesn't select an particular action, the parser generator reports a
conflict and selects a default action. By default a <em>shift</em> is used, rather
than a <em>reduce</em>. With a <em>reduce-reduce</em> conflict the default action is to
reduce by the rule listed first in the grammar.
    <li> In cases where input is not structured according to the rules of the
grammar, a <em>syntactic error</em> is observed. Error recovery may be attempted,
to allow the parser to continue parsing. This is a desirable characteristic
since it provides the user of a program with a full syntactic error report,
rather than one error at a time.
    <li> Following the analysis of the grammar, code is generated and the
parsing algorithm (implemented in the parser's <code>parse()</code> function) 
processes input according to the tables generated by the parser generator. 
    </ul>
<p>
All the above phases are illustrated and discussed in the next
sections. Additional details of the parsing process can be found in various
books about compiler construction, e.g., in Aho, Sethi and Ullman's (2003)
book <strong>Compilers</strong> (Addison-Wesley).
<p>
In the sections below, the following grammar is used to illustrate the
various phases:
        <pre>

    %token NR
    
    %left '+'
    
    %%
    
    start:
        start expr
    |
        // empty
    ;
    
    expr:
        NR
    |
        expr '+' expr
    ;
        
</pre>

    The grammar is interesting as it has a rule containing an empty
alternative and because it harbors a shift-reduce conflict. The shift-reduce
conflict is solved by explictly assigning a priority and association to the
<code>'+'</code> token.
<p>
The analysis starts by defining an additional rule, which is recognized
(reduced) at end of input. This rule and the rules specified in the grammar
together define what is known as the <em>augmented grammar</em>. In the coming
sections the symbol <code>$</code> is used to indicate `end of input'. From the above
grammar the following augmented grammar is derived:
        <pre>

    1.  start:      start expr
    2.  start:      // empty
    3.  expr:       NR
    4.  expr:       expr '+' expr
    5.  start_$:    start   (input ends here)
        
</pre>

<p>
<strong>bisonc++</strong> itself produces an extensive analysis of any grammar it is offered
when the option <code>--construction</code> is provided.
<p>
<a name="l104"></a>
<h3>7.0.1: The FIRST Sets</h3>
    The <code>FIRST</code> set defines all terminal tokens that can be encountered when
beginning to recognize a grammatical symbol. For each grammatical symbol
(terminal and nonterminal) a <code>FIRST</code> set can be determined as follows:
    <ul>
    <li> The <code>FIRST</code> set of a terminal symbol is the symbol itself.
    <li> The <code>FIRST</code> set of an empty alternative is the empty set. The empty
        set is indicated by &epsilon;
     and is considered an actual element of the
        <code>FIRST</code> set (So, a <code>FIRST</code> set could contain two elements: 
        <code>'+'</code> <em>and</em> &epsilon;
    ).
    <li> If X has a production rule <code>X: X1 X2 X3..., Xi, ...Xn</code>, then
        initialize <code>FIRST(X)</code> to empty (i.e., not even holding &epsilon;
    ). Then, 
        for each Xi (1..n):
        <ul>
        <li> add <code>FIRST(Xi)</code> to <code>FIRST(X)</code>
        <li> stop when <code>FIRST(Xi)</code> does not contain &epsilon;
<p>
</ul>
        If <code>FIRST(Xn)</code> does not contain &epsilon;
     remove &epsilon;
     from <code>FIRST(X)</code> (unless
analyzing another production rule) &epsilon;
     is already part of <code>FIRST(X)</code>.
    </ul>
<p>
When starting this algorithm, only the nonterminals need to be
considered. Also, required <code>FIRST</code> sets may not yet be available. Therefore
the above algorithm iterates over all nonterminals until no changes were
observed. In the algorithm <code>$</code> is not considered. 
<p>
Applying the above algorithm to the rules of our grammar we get:
    <table>

    <td colspan=4><hr></td>

    
<tr>
<td> nonterminal</td><td> rule</td><td>  </td><td> FIRST set</td>
 
</tr>

    <td colspan=4><hr></td>

    
<tr>
<td> <code>start_$</code></td><td> <code>start</code></td><td>  </td><td> not yet available</td>
 
</tr>

    
<tr>
<td> <code>start</code></td><td> <code>start expr</code></td><td>  </td><td> not yet available</td>
 
</tr>

    
<tr>
<td> <code>start</code></td><td> <code>// empty</code></td><td>  </td><td> &epsilon;
    </td>
 
</tr>

    
<tr>
<td> <code>expr</code></td><td> <code>NR</code></td><td>  </td><td> <code>NR</code></td>
 
</tr>

    
<tr>
<td> <code>expr</code></td><td> <code>expr '+' expr</code></td><td>  </td><td> <code>NR</code></td>
 
</tr>

    <td colspan=4><hr></td>

    
<tr>
<td> changes in the next cycle:</td> 
</tr>

    
<tr>
<td> <code>start</code></td><td> <code>start expr</code></td><td>  </td><td> <code>NR</code> &epsilon;
    </td>
 
</tr>

    
<tr>
<td> <code>start</code></td><td> <code>// empty</code></td><td>  </td><td> <code>NR</code> &epsilon;
    </td>
 
</tr>

    <td colspan=4><hr></td>

    
<tr>
<td> changes in the next cycle:</td> 
</tr>

    
<tr>
<td> <code>start_$</code></td><td> <code>start</code></td><td>  </td><td> <code>NR</code> &epsilon;
    </td>
 
</tr>

    <td colspan=4><hr></td>

    
<tr>
<td> no further changes</td> 
</tr>

    
</table>
<p>
<a name="l105"></a>
<h3>7.0.2: The States</h3>
    Having determined the <code>FIRST</code> set, <strong>bisonc++</strong> determines the
<em>states</em> of the grammar. The analysis starts at the augmented grammar rule
and proceeds until all possible states have been determined. 
In this analysis the concept of the <em>dot</em> symbol is used. The <em>dot</em> shows
the position we are at when analyzing production rules defined by a grammar.
Using the provided example grammar the analysis proceeds as follows:
    <ul>
    <li> State 0: <code>start_$ -&gt; . start</code><br>
        At this point we haven't seen anything yet. The <em>dot</em> is before the
grammar's start symbol. The above is called an <em>item</em> and the initial set of
items of a state is called the set of <em>kernel items</em>. Except for the start
rule, kernel items never have a dot before the very first symbol of a rule. In
this particular state there's only one kernel item. Items are indexed, so this
item receives index 0. Beyond, item indices are shown together with the items
themselves. If a non-terminal follows immediately to the right of the dot,
then all production rules of that non-terminal are added to the state as
non-kernel items. Non-kernel items always have their dots at the very first
position. Adding non-kernel items is a recursive process. If the rules of thus
added items also show non-terminals to the right of the dot, then the
production rules of those non-terminals are added too (unless they were
already added). 
<p>
The above kernel item results in the addition of the following non-kernel
items:
        <ul>
        <li> item 1: <code>start -&gt;  . start expr</code>
        <li> item 2: <code>start -&gt;  . </code>
        </ul>
<p>
From each of the items new states may be derived. New states are reached
when the symbol to the right of the dot has been recognized. In that case a
<em>transition</em> (a <em>goto</em>) to the next state takes place, where the dot has
moved one postition to the right, defining a kernel item of the new
state. Once the dot has reached the end of the rule, a <em>reduction</em> may take
place. Following a reduction a transition based on the <em>Left Hand Side</em>
(<code>LHS</code>) of the reduced production rule is performed. This procedure is
discussed in more detail in section <a href="bisonc++07.html#PARSING">7.0.5</a>.
<p>
Looking at the current state's items, two actions are possible:
    <ul>
    <li> On <code>start</code>, to a state in which <code>start</code> has been seen (state 1)
    <li> By default, a reduction by the rule <code>start -&gt;  . </code>
    </ul>
<p>
<li> State 1: kernel items:
        <ul>
        <li> item 0: <code>start_$ -&gt; start  .</code>
        <li> item 1: <code>start -&gt; start  . expr</code>
        </ul>
        Since <code>expr</code> is a non-terminal to the right of the dot, we add
        all <code>expr</code> rules as this state's non-kernel items:
        <ul>
        <li> item 2: <code>expr -&gt;  . NR</code>
        <li> item 3: <code>expr -&gt;  . expr '+' expr</code>
        </ul>
    This state becomes the <em>accepting</em> state: if EOF is reached in this
state, the <code>start_$</code> rule has been recognized, and so the input was
syntactically correct. But in this state  transitions to other states are also
possible:
        <ul>
        <li> On <code>expr</code> to state 2
        <li> On NR to state 3
        </ul>
<p>
<li> State 2: kernel items:
        <ul>
        <li> item 0: <code>start -&gt; start expr  .</code>
        <li> item 1: <code>expr -&gt; expr  . '+' expr</code>
        </ul>
        No non-terminal symbols appear to the right of the dots in these
items, so no non-kernel items are added to this state. Transitions from this
state are:
        <ul>
        <li> On <code>'+'</code> to state 4
        <li> Or reduce to <code>start</code> according to its first item (removing
            two elements from the parser's stack).
        </ul>
<p>
<li> State 3: kernel items:
        <ul>
        <li> item 0: <code>expr -&gt; NR  .</code>
        </ul>
        In this state only one action is possible: a reduction to <code>expr</code>
        (removing one element from the parser's stack).
<p>
<li> State 4: kernel item:
        <ul>
        <li> item 0: <code>expr -&gt; expr '+'  . expr</code>
        </ul>
        Since <code>expr</code> is a non-terminal to the right of the dot, we add
        all <code>expr</code> rules as this state's non-kernel items:
        <ul>
        <li> item 1: <code>expr -&gt; . NR</code>
        <li> item 2: <code>expr -&gt; . expr '+'  expr</code>
        </ul>
        In this state the following transitions are possible:
        <ul>
        <li> On <code>expr</code> to state 5 
        <li> On <code>NR</code> we reach the situation <code>expr -&gt; NR .</code> which has
        already been encountered at state 3. That's OK, so on <code>NR</code> there is
        a transition to state 3.
        </ul>
        Note that in order to return to a previously defined state that state
must have exactly the required kernel items. So, if state 3 would contain
multiple kernel items, a new state would have been required, merely having the
<code>expr -&gt; NR .</code> kernel item.
<p>
<li> State 5: kernel items:
        <ul>
        <li> item 0: <code>expr -&gt; expr '+' expr  .</code>
        <li> item 1: <code>expr -&gt; expr . '+' expr</code>
        </ul>
        In this state two actions are possible:
        <ul>
        <li> On <code>'+'</code> to state 4
        <li> Or reduce to <code>expr</code> according to its first item (removing three
            elements from the parser's stack).
        </ul>
        As explained in the next section this state's first action is never
        selected: in this state only the reduction is selected.
    </ul>
<p>
<a name="LOOKAHEAD"></a><a name="l106"></a>
<h3>7.0.3: The Look-ahead Sets</h3>
    In the previous section a grammer was discussed whose fifth state contained
two items: one resulting in a shift-action, the other resulting in a
reduce-action. This state contained these two items:
        <ul>
        <li> item 0: <code>expr -&gt; expr '+' expr  .</code>
        <li> item 1: <code>expr -&gt; expr . '+' expr</code>
        </ul>
    Although this state in theory defines two different actions, in practice
only one is used. This is a direct consequence of the <code>%left '+'</code>
specification, which is explained in this and the next section.
<p>
When analyzing a grammar all states that can be reached from the augmented
start rule are determined. In the current grammar's fifth state <strong>bisonc++</strong> must
decide which action to take: should it shift on <code>'+'</code> or should it reduce
according to the item `<code>expr -&gt; expr '+' expr .</code>'? What choice will <strong>bisonc++</strong>
make?
<p>
Here the fact that <strong>bisonc++</strong> implements a parser for a <em>Look Ahead Left to Right
(1)</em> (LALR(1)) grammar becomes relevant. <strong>Bisonc++</strong> computes <em>look-ahead sets</em> to
determine which alternative to select when confronted with a choice. The
look-ahead set can be used to favor one action over another when generating
tables for the parsing function.
<p>
Sometimes the look-ahead sets allow <strong>bisonc++</strong> simply to remove one action from the
set of possible actions. When <strong>bisonc++</strong> is called to process the example grammar
while specifying the <code>--construction</code> option state five <em>only</em> shows the
reduction and <em>not</em> the shifting action, as <strong>bisonc++</strong> has removed that latter
action from the action set. In state five the choice is between shifting a
<code>'+'</code> token on the stack, or reducing the stack according to the rule
    <pre>

        expr -&gt; expr '+' expr
    
</pre>
 
    Here, as we will shortly see, the <code>'+'</code> is <em>also</em> an element of the
<em>look-ahead set</em> of the reducible item, creating a conflict: what to do
on <code>'+'</code>?
<p>
In this case the grammar designer has provided <strong>bisonc++</strong> with a way out: the
<code>%left</code> directive tells <strong>bisonc++</strong> to favor a reduction over a shift, and so it
removed <code>expr -&gt; expr . '+' expr</code> from its set of actions in state five.
<p>
<a name="l107"></a>
<h4>7.0.3.1: The look-ahead token</h4>
        The <strong>bisonc++</strong> parser does <em>not</em> always perform a reduction when a state is reached
where an item has its dot position beyond the last element of its production
rule. For most languages such a simple strategy is incorrect. Instead, when a
reduction is possible, the parser sometimes `looks ahead' to the next token to
decide what to do.
<p>
Whenever a token is read, it is not immediately shifted; first it becomes the
<em>look-ahead</em> token, which is not yet shifted on the stack. This allows the
parser to perform one or more reductions, with the look-ahead token still
waiting to be processed. Only when all available reductions have been
performed the look-ahead token is shifted on the stack. The phrase `all
<em>available</em> reductions' does not necessarily mean all <em>possible</em>
reductions. Depending on the look-ahead token, a shift rather than a reduce
may be performed in states in which both actions are possible.
<p>
Here is a simple case where a look-ahead token is required. The production
rules define expressions which may contain binary addition operators and
postfix unary factorial operators (`<code>!</code>'), as well as parentheses for
grouping expressions:
    <pre>

    expr:     
        term '+' expr
    | 
        term
    ;

    term:     
        '(' expr ')'
    | 
        term '!'
    | 
        NUMBER
    ;
        
</pre>

    Suppose that the tokens `<code>1 + 2</code>' have been read and shifted; what
should be done? If the following token is `)', then the first three
tokens must be reduced, forming an <code>expr</code>. This is the only valid course,
because shifting the `)' would produce the sequence of symbols
    <pre>

    term ')'
    
</pre>

    which is not syntactically correct.
<p>
But if the next token is `<code>!</code>', then that token must be shifted so that
`<code>2 !</code>' can be reduced to recognize a <code>term</code>. If in this case the parser
would perform a reduction then `<code>1 + 2</code>' would become an <code>expr</code>. In that
case the `<code>!</code>' can't be shifted because doing so would result in the
sequence 
    <pre>

    expr '!'
    
</pre>

    which is also syntactically incorrect.
<p>
<a name="l108"></a>
<h4>7.0.3.2: How look-ahead sets are determined</h4>
        Once the items of all the grammar's states have been determined the LA sets
for the states' items are computed. Starting from the LA set of the kernel
item of state 0 (representing the augmented grammar's production rule
<code>S_$: . S</code>, where <code>S</code> is the grammar's start rule) the LA sets of all
items of all of the grammar's states are determined. By definition, the LA set
of state 0's kernel item equals <code>$</code>, representing end-of-file. 
<p>
Starting from the function <code>State::determineLAsets</code>, which is called for
state 0, the LA sets of all items of all states are computed.
<p>
For each state, the LA sets of its items are computed first. Once they have
been computed, the LA sets of items from where transitions to other states are
possible are then propagated to the matching kernel items of those destination
states. When the LA sets of kernel items of those destination states are
enlarged then their state indices are added to a set <code>todo</code>. LA sets of the
items of states whose indices are stored in the <code>todo</code> set are (re)computed
(by calling <code>determineLAsets</code> for those states) until <code>todo</code> is empty, at
which point all LA sets have been computed. Initially <code>todo</code> only contains
0, the index of the initial state, representing the augmented grammar's
production rule.
<p>
To compute the LA sets of a state's items the LA set of each of its kernel
items is distributed (by the member <code>State::distributeLAsetOf</code>) over the
items which are implied by the item being considered. E.g., for item <code>X: a
. Y z</code>, where <code>a</code> and <code>z</code> are any sequence of grammar symbols and <code>X</code>
and <code>Y</code> are non-terminal symbols, all of <code>Y's</code> production rules are added
as new items to the current state.
<p>
Then the member <code>distributeLAsetOfItem(idx)</code> matches the item's rule
specification with the specification <code>a.Bc</code>, where <code>a</code> and <code>c</code> are
(possibly empty) sequences of grammatical symbols, and <code>B</code> is a (possibly
empty) non-terminal symbol appearing immediately to the right of the item's
dot position. if <code>B</code> is empty then there are no additional production rules
and <code>distributeLAsetOf</code> may return. Otherwise, the set <code>b = FIRST(c)</code> is
computed. This set holds all symbols which may follow <code>B</code>. If <code>b</code> contains
&epsilon;
     (i.e., the element representing the empty set), then the currently
defined LA set of the item can also be observed. In that case &epsilon;
     is
removed, and the currently defined LA set is added to <code>b</code>. Finally, the LA
sets of all items representing a production rule for <code>B</code> are inspected: if
<code>b</code> contains unique elements compared to the LA sets of those items, then
the unique elements of <code>b</code> are added to the LA sets of those items. Finally,
<code>distributeLAsetOfItem</code> is recursively called for those items whose LA sets
were enlarged.
<p>
Once the LA sets of the items of a state have thus been computed,
<code>inspectTransitions</code> is called to propagate the LA sets of items from where
transitions to other states are possible to the affected (kernel) items of
those other (destination) states. The member <code>inspectTransitions</code> inspects
all <code>Next</code> objects of the current state's <code>d_nextVector</code>. Next objects
provide
    <ul>
    <li>  the state index of a state to transfer to from the current state;
    <li> a size_t vector of item transitions. Each element is the index of an
        item in the current state (the source-item), its index is the index
        of a (kernel) item of the state to transfer to (the destination
        index). 
    </ul>
  If the LA set of a destination item can be enlarged from the LA set of the
source item then the LA sets of the destination state's items must be
recomputed. This is realized by inserting the destation state's index into the
`todo' set.
<p>
To illustrate an LA-set computation we will now compute the LA sets of (some
of) the items of the states of the grammar introduced at the beginning of this
chapter. Its augmented grammar consists of the following production rules:
        <pre>

    1.  start:      start expr
    2.  start:      // empty
    3.  expr:       NR
    4.  expr:       expr '+' expr
    5.  start_$:    start
        
</pre>

When analyzing this grammer, we found the following five states, consisting of 
several items and transitions (kernel items are marked with K following their
item indices). Next to the items, where applicable, the goto-table is shown:
the state to go to when the mentioned grammatical symbol has been recognized:
    <pre>

                                            Goto table
                                            -----------
State 0:                                    start
    0K:     start_$ -&gt;  . start               1
    1:      start   -&gt;  . start expr          1
    2:      start   -&gt;  . 

State 1:                                    expr    NR
    0K:     start_$ -&gt;  start  .         
    1K:     start   -&gt;  start  . expr         2
    2:      expr    -&gt;  . NR                         3
    3:      expr    -&gt;  . expr '+' expr

State 2:                                     '+'
    0K:     start   -&gt; start expr  .
    1K:     expr    -&gt; expr  . '+' expr       4

State 3: 
    0K:     expr    -&gt; NR  .

State 4:                                    expr    NR
    0K:     expr    -&gt; expr '+'  . expr       5
    1:      expr    -&gt; . NR                          3
    2:      expr    -&gt; . expr '+'  expr       5

State 5:                                     '+'
    0K:     expr    -&gt; expr '+' expr  .     
    1K:     expr    -&gt; expr . '+' expr        4
    
</pre>

<p>
Item 0 of state 0 by definition has LA symbol $, and LA computation therefore
always starts at item 0 of state 0. The interesting part of the LA set
computation is encountered in the recursive member <code>distributeLAsets</code>: 
    <pre>

distributeLAsetsOfItem(0)
  start_$ -&gt; . start:     LA: {$}, B: start, c: {}, so b: {$}

  items 1 and 2 refer to production rules of B (start) and are inspected:

  1: LA(1): {}: b contains unique elements. Therefore: 
    LA(1) = {$}
    distributeLAsetsOfItem(1):
      start -&gt; . start expr: LA: {$}, B: start, c: {expr}, so b: {NR}
      inspect items 1 and 2 as they refer to production rules of B (start):

      1: LA(1): {}: b contains unique elements. Therefore: 
        LA(1) = {$,NR}
        distributeLAsetsOfItem(1)
          start -&gt; . start expr: LA: {$,NR}, B: start, c: {expr}, so b: {NR}
          inspect items 1 and 2 as they refer to prod. rules of B (start):

          1: LA(1): {$,NR}, so b does not contain unique elements: done

          2: LA(2): {}, b contains unique elements
            LA(2) = {NR}
            distributeLAsetsOfItem(2)
              start -&gt; .: LA: {NR}, B: -, c: {}, so b: {NR}
              inspect items 1 and 2 as they refer to prod. rules of B (start):

              1: LA(1): {$,NR}, b does not contain unique elements: done

              2: LA(2): {NR}, so b does not contain unique elements: done

      2: LA(2): {NR}, so b does not contain unique elements: done

  2: LA(2): {NR}: b contains unique elements. Therefore:
    LA(2) = {$,NR}
    distributeLAsetsOfItem(2)
      start -&gt; .: LA: {$,NR}, B: -, c: {}
      B empty, so return.
    
</pre>

So, item 0 has LA set <code>{$}</code>, items 1 and 2 have LA sets <code>{$,NR}</code>.
<p>
The next step involves propagating the LA sets to kernel items of the states
to where transitions are possible:
        <ul>
    <li> Item 0, state 0 transits to item 0 state 1. Item 0 of state 1's
current LA set is empty, so it receives LA set <code>{$}</code>, and 1 (state 1's
index) is inserted into the <code>todo</code> set.
    <li> Item 1, state 0 transits to item 1 state 1. Item 1 of state 1's
current LA set is empty, so it receives LA set <code>{$,NR}</code>, and 1 (state 1's
index) is inserted into the <code>todo</code> set.
        </ul>
<p>
Following this LA set propagation the LA sets of all items of state 1 are
computed, which in turn is followed by LA propagation to other states (states
2 and 3), etc. etc.
<p>
In this grammar there are no transitions to the current state (i.e.,
transitions from state x to state x). If such transitions are encountered then
they can be ignored by <code>inspectTransitions</code> as the LA sets of the items of a
state have already be computed by the time <code>inspectTransitions</code> is called.
<p>
<a name="l109"></a>
<h3>7.0.4: The Final Transition Tables</h3>
        <a name="l110"></a>
<h4>7.0.4.1: Preamble</h4>
        The member function <code>parse()</code> is implemented using a finite-state
machine. The values pushed on the parser stack are not simply token type
codes; they represent the entire sequence of terminal and nonterminal symbols
at or near the top of the stack. The current state collects all the
information about previous input which is relevant to deciding what to do
next.
<p>
Each time a look-ahead token is read, the current parser state together with
the current (not yet processed) token are looked up in a table. This table
entry can say <em>Shift the token</em>. This also specifies a new parser state,
which is then pushed onto the top of the parser stack. Or it can say <em>Reduce
using rule number n</em>. This means that a certain number of tokens or groupings
are taken off the top of the stack, and that the rule's grouping becomes the
`next token' to be considered. That `next token' is then used in combination
with the state then at the stack's top, to determine the next state to
consider. This (next) state is then again pushed on the stack, and a new token
is requested from the lexical scanner, and the process repeats itself.
<p>
There are two special situations the parsing algorithm must consider:
    <ul>
    <li> First, the lexical scanner may reach <em>end-of-input</em>. If the current
state on top of the parser's stack is the start-state, then the reduction
(which is called for in this situation) is in fact the (successful) end of the
parsing process, and <code>parse()</code> returns the value 0, indicating a successful
parsing. 
    <li> There is one other alternative: the table can say that the 
token is erroneous in the current state. This causes error processing to begin
(see chapter <a href="bisonc++08.html#RECOVERY">8</a>).
    </ul>
<p>
Once <strong>bisonc++</strong> has successfully analyzed the grammar it generates the tables that
are used by the parsing function to parse input according to the provided
grammar. Each state results in a <em>state transition table</em>. For the example
grammar used so far there are five states. Each table consists of rows having
two elements. The meaning of the elements depends on their position in the
table. 
    <ul>
    <li> For the <em>first</em> row, 
        <ul>
        <li> the first element indicates the <em>type</em> of the
state. The following types are recognized:
    <table>

    
<tr>
<td> NORMAL</td><td> Despite its name, it's not used</td>
 
</tr>

    
<tr>
<td> ERR_ITEM</td><td> The state allows error recovery</td>
 
</tr>

    
<tr>
<td> REQ_TOKEN</td><td> The state requires a token <br>
                        (which may already be available)</td>
 
</tr>

    
<tr>
<td> ERR_REQ</td><td> combines ERR_ITEM and REQ_TOKEN</td>
 
</tr>

    
<tr>
<td> DEF_RED</td><td> This state has a default reduction</td>
 
</tr>

    
<tr>
<td> ERR_DEF</td><td> combines ERR_ITEM and DEF_RED</td>
 
</tr>

    
<tr>
<td> REQ_DEF</td><td> combines REQ_TOKEN and  DEF_RED</td>
 
</tr>

    
<tr>
<td> ERR_REQ_DEF</td><td> combines ERR_ITEM, REQ_TOKEN and DEF_RED</td>
 
</tr>

    
</table>
        <li> the second element indicates the index of the table's last
        element. 
        </ul>
    <li> For the <em>last</em> row,
        <ul>
        <li> the first element stores the current token (it is not used when
the option <code>--thread-safe</code> was specified)
        <li> the second element defines the action to perform. A positive
value indicates a shift to the indicated state; a negative value a reduction
according to the indicated rule number, disregarding its sign (note that it's
rule <em>number</em>, rather than rule <em>offset</em>; zero indicates the input is
accepted as correct according to the parser's grammar.
        )
    <li> For all intermediate remaining rows:
        the first element stores the value of a required token for the action
specified in the second element, similar to the way an action is specified in
the last row. Symbolic values (like <code>PARSE_ACCEPT</code> rather than 0) may be
used as well.
    </ul>
    </ul>
    Here are the tables defining the five states of the example grammar 
as they are generated by <strong>bisonc++</strong> in the file containing the parsing function:
        <pre>

    SR__ s_0[] =
    {
        { { DEF_RED}, {  2} },         
        { {     258}, {  1} }, // start
        { {       0}, { -2} },         
    
    };
    
    SR__ s_1[] =
    {
        { { REQ_TOKEN}, {            4} },        
        { {       259}, {            2} }, // expr
        { {       257}, {            3} }, // NR  
        { {     _EOF_}, { PARSE_ACCEPT} },        
        { {         0}, {            0} },        
    
    };
    
    SR__ s_2[] =
    {
        { { REQ_DEF}, {  2} },       
        { {      43}, {  4} }, // '+'
        { {       0}, { -1} },       
    
    };
    
    SR__ s_3[] =
    {
        { { DEF_RED}, {  1} }, 
        { {       0}, { -3} }, 
    
    };
    
    SR__ s_4[] =
    {
        { { REQ_TOKEN}, { 3} },        
        { {       259}, { 5} }, // expr
        { {       257}, { 3} }, // NR  
        { {         0}, { 0} },        
    
    };
    
    SR__ s_5[] =
    {
        { { REQ_DEF}, {  1} }, 
        { {       0}, { -4} }, 
    
    };
        
</pre>

<p>
<a name="PARSING"></a><a name="l111"></a>
<h3>7.0.5: Processing Input</h3>
    <strong>Bisonc++</strong> implements the parsing function in the member function <code>parse()</code>. This
function obtains its tokens from the member <code>lex()</code> and processes all tokens
until a syntactic error, a non-recoverable error, or the end of input is
encountered. 
<p>
The algorithm used by <code>parse()</code> is the same, irrespective of the used
grammar. In fact, the <code>parse()</code> member's behavior is completely determined
by the tables generated by <strong>bisonc++</strong>. 
<p>
The parsing algorithm is known as the <em>shift-reduce</em> (S/R) algorithm, and it
allows <code>parse()</code> to perform two actions while processing series of tokens:
    <ul>
    <li> When a token is received in a state in which that token is required
for a transition to another state (e.g., a <code>NR</code> token is observed in
state 1 of the example's grammar) a transition to state 3 is performed.
    <li> When a state is reached which calls for a (default) reduction (e.g.,
state 3 of the example's grammar) a reduction is performed.
    </ul>
<p>
The parsing function maintains two stacks, which are manipulated by the above
two actions: a state stack and a value stack. These stacks are not accessible
to the parser: they are private data structures defined in the parser's base
class. The parsing member <code>parse()</code> may use the following member functions
to manipulate these stacks:
    <ul>
    <li><code>push__(stateIdx)</code> pushes <code>stateIdx</code> on the state stack and pushes
the current semantic value (i.e., <code>LTYPE_ d_val__</code>) on the value stack;
    <li><code>pop__(size_t count = 1)</code> removes <code>count</code> elements from the two
stacks;
    <li><code>top__()</code> returns the state currently on top of the state stack;
    </ul>
<p>
Apart from the state- and semantic stacks, the S/R algorithm itself sometimes
needs to push a token on a two-element stack. Rather than using a formal
stack, two variables (<code>d_token__</code> and <code>d_nextToken__</code>) are used to
implement this little token-stack. The member function <code>pushToken__()</code>
pushes a new value on the token stack, the member <code>popToken__()</code>
pops a previously pushed value from the token stack. At any time,
<code>d_token__</code> contains the topmost element of the token stack.
<p>
The member <code>nextToken()</code> determines the next token to be processed. If the
token stack contains a value it is returned. Otherwise, <code>lex()</code> is called to
obtain the next token to be pushed on the token stack.
<p>
The member <code>lookup()</code> looks up the current token in the current state's
<code>SR__</code> table. For this a simple linear search algorithm is used. If
searching fails to find an action for the token an <code>UNEXPECTED_TOKEN__</code>
exception is thrown, which starts the error recovery. If an action was found, 
it is returned.
<p>
Rules may have actions associated with them. These actions are executed when a
grammatical rule has been completely recognized. This is always at the end of
a rule: mid-rule actions are converted by <strong>bisonc++</strong> into pseudo nonterminals,
replacing mid-rule action blocks by these pseudo nonterminals. The pseudo
nonterminals show up in the verbose grammar output as rules having LHSs
starting with <code>#</code>. So, once a rule has been recognized its action (if
defined) is executed. For this the member function <code>executeAction()</code> is
available. 
<p>
Finally, the token stack can be cleared using the member <code>clearin()</code>. 
<p>
Now that the relevant support functions have been introduced, the S/R
algorithm itself turns out to be a fairly simple algorithm. First, the
parser's stack is initialized with state 0 and the token stack is
cleared. Then, in a never ending loop:
    <ul>
    <li> If a state needs a token (i.e., <code>REQ_TOKEN</code> has been specified for
that state), <code>nextToken()</code> is called to obtain the next token;
    <li> From the token and the current state <code>lookup()</code> determines the next
action; 
    <li> If a shifting action was called for  the next state is pushed on
the stack and the token is popped off the token stack.
    <li> If a reduction was called for that rule's action block is executed
followed by a reduction of the production rule (performed by <code>reduce__()</code>):
the semantic and state stacks are reduced by the number of elements found in
that production rule, and the production rule's LHS is pushed on the token
stack
    <li> If the state/token combination indicates that the input is accepted
(normally: when <code>EOF</code> is encountered in state 1) then the parsing function
terminates, returning 0.
    </ul>
<p>
The following table shows the S/R algorithm in action when the example grammar
is given the input <code>3 + 4 + 5</code>. The first column shows the (remaining)
input, the second column the current token stack (with <code>-</code> indicating an
empty token stack), the third column the state stack. The fourth column
provides a short description. The leftmost elements of
the stacks represent the tops of the stacks. The information shown below is
also (in more elaborate form) shown when the <code>--debug</code> option is provided to
<strong>Bisonc++</strong> when generating the parsing function.
<p>
<table>

    <td colspan=7><hr></td>

    
<tr>
<td> remaining input</td><td>  </td><td> token stack</td><td>  </td><td> state stack</td>
                                              <td>  </td><td> description</td>
 
</tr>

    <td colspan=7><hr></td>

    
<tr>
<td> <code>3 + 4 + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>        0</code></td>
              <td> </td><td> initialization</td>
 
</tr>

    
<tr>
<td> <code>3 + 4 + 5</code></td><td> </td><td> <code>start</code></td><td> </td><td> <code>        0</code></td>
              <td> </td><td> reduction by rule 2</td>
 
</tr>

    
<tr>
<td> <code>3 + 4 + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> shift `start'</td>
 
</tr>

    
<tr>
<td> <code>  + 4 + 5</code></td><td> </td><td> <code>NR</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> obtain NR token</td>
 
</tr>

    
<tr>
<td> <code>  + 4 + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>    3 1 0</code></td>
              <td> </td><td> shift NR</td>
 
</tr>

    
<tr>
<td> <code>  + 4 + 5</code></td><td> </td><td> <code>expr</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> reduction by rule 3</td>
 
</tr>

    
<tr>
<td> <code>  + 4 + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>    2 1 0</code></td>
              <td> </td><td> shift `expr'</td>
 
</tr>

    
<tr>
<td> <code>    4 + 5</code></td><td> </td><td> <code>+</code></td><td> </td><td> <code>    2 1 0</code></td>
              <td> </td><td> obtain `+' token</td>
 
</tr>

    
<tr>
<td> <code>    4 + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>  4 2 1 0</code></td>
              <td> </td><td> shift `+'</td>
 
</tr>

    
<tr>
<td> <code>      + 5</code></td><td> </td><td> <code>NR</code></td><td> </td><td> <code>  4 2 1 0</code></td>
              <td> </td><td> obtain NR token</td>
 
</tr>

    
<tr>
<td> <code>      + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>3 4 2 1 0</code></td>
              <td> </td><td> shift NR</td>
 
</tr>

    
<tr>
<td> <code>      + 5</code></td><td> </td><td> <code>expr</code></td><td> </td><td> <code>  4 3 1 0</code></td>
              <td> </td><td> reduction by rule 3</td>
 
</tr>

    
<tr>
<td> <code>      + 5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>5 4 3 1 0</code></td>
              <td> </td><td> shift `expr'</td>
 
</tr>

    
<tr>
<td> <code>        5</code></td><td> </td><td> <code>+</code></td><td> </td><td> <code>5 4 3 1 0</code></td>
              <td> </td><td> obtain `+' token</td>
 
</tr>

    
<tr>
<td> <code>        5</code></td><td> </td><td> <code>expr +</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> reduction by rule 4</td>
 
</tr>

    
<tr>
<td> <code>        5</code></td><td> </td><td> <code>+</code></td><td> </td><td> <code>    2 1 0</code></td>
              <td> </td><td> shift `expr'</td>
 
</tr>

    
<tr>
<td> <code>        5</code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>  4 2 1 0</code></td>
              <td> </td><td> shift '+'</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>NR</code></td><td> </td><td> <code>  4 2 1 0</code></td>
              <td> </td><td> obtain NR token</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>3 4 2 1 0</code></td>
              <td> </td><td> shift NR</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>expr</code></td><td> </td><td> <code>  4 2 1 0</code></td>
              <td> </td><td> reduction by rule 3</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>-</code></td><td> </td><td> <code>5 4 2 1 0</code></td>
              <td> </td><td> shift `expr'</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>EOF</code></td><td> </td><td> <code>5 4 2 1 0</code></td>
              <td> </td><td> obtain EOF</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>expr EOF</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> reduction by rule 4</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>EOF</code></td><td> </td><td> <code>    2 1 0</code></td>
              <td> </td><td> shift `expr'</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>start EOF</code></td><td> </td><td> <code>    2 1 0</code></td>
              <td> </td><td> reduction by rule 1</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>EOF</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> shift `start'</td>
 
</tr>

    
<tr>
<td> <code>         </code></td><td> </td><td> <code>EOF</code></td><td> </td><td> <code>      1 0</code></td>
              <td> </td><td> ACCEPT</td>
 
</tr>

    <td colspan=7><hr></td>


</table>
<p>
<a name="SHIFTREDUCE"></a><a name="l112"></a>
<h2>7.1: Shift/Reduce Conflicts</h2>
Suppose we are parsing a language which has <code>if</code> and <code>if-else</code>
statements, with a pair of rules like this:
        <pre>

    if_stmt:
        IF '(' expr ')' stmt
    | 
        IF '(' expr ')' stmt ELSE stmt
    ;
        
</pre>

    Here we assume that <code>IF</code> and <code>ELSE</code> are terminal symbols for specific
keywords, and that <code>expr</code> and <code>stmnt</code> are defined non-terminals.
<p>
When the <code>ELSE</code> token is read and becomes the look-ahead token, the contents
of the stack (assuming the input is valid) are just right for <em>reduction</em> by
the first rule. But it is also legitimate to <em>shift</em> the <code>ELSE</code>, because
that would lead to eventual reduction by the second rule.
<p>
This situation, where either a shift or a reduction would be valid, is called
a <code>shift/reduce</code> conflict. <strong>Bisonc++</strong> is designed to resolve these conflicts
by <em>implementing</em> a shift, unless otherwise directed by operator precedence
declarations. To see the reason for this, let's contrast it with the other
alternative.
<p>
Since the parser prefers to shift the <code>ELSE</code>, the result is to attach the
<em>else-clause</em> to the innermost if-statement, making these two inputs
equivalent:
        <pre>

    if (x) if (y) then win(); else lose();

    if (x) 
    {
        if (y) then win(); else lose(); 
    }
        
</pre>

    But if the parser would perform a <em>reduction</em> whenever possible rather
than a <em>shift</em>, the result would be to attach the <em>else-clause</em> to the
outermost if-statement, making these two inputs equivalent:
        <pre>

    if (x) if (y) then win(); else lose();

    if (x) 
    {
        if (y) win(); 
    }
    else 
        lose();
        
</pre>

    The conflict exists because the grammar as written is <em>ambiguous</em>:
<em>either</em> parsing of the simple nested if-statement is legitimate. The
established convention is that these ambiguities are resolved by attaching the
else-clause to the innermost if-statement; this is what <strong>bisonc++</strong> accomplishes
by implementing a shift rather than a reduce. This
particular ambiguity was first encountered in the specifications of Algol 60
and is called the <em>dangling else</em> ambiguity.
<p>
To avoid warnings from <strong>bisonc++</strong> about predictable, legitimate shift/reduce
conflicts, use the <code>%expect n</code> directive. There will be no warning as long
as the number of shift/reduce conflicts is exactly <code>n</code>. See section
<a href="bisonc++05.html#EXPECT">5.5.5</a>.
<p>
The definition of <code>if_stmt</code> above is solely to blame for the conflict, but
the plain <code>stmnt</code> rule, consisting of two recursive alternatives will of
course never be able to match actual input, since there's no way for the
grammar to eventually derive a sentence this way. Adding one non-recursive
alternative is enough to convert the grammar into one that <em>does</em> derive
sentences. Here is a complete <strong>bisonc++</strong> input file that actually shows the
conflict:
    <pre>
%token IF ELSE VAR

%%

stmt:     
    VAR ';'
|
    IF '(' VAR ')' stmt
|
    IF '(' VAR ')' stmt ELSE stmt
;


</pre>

<p>
Looking again at the dangling else problem note that there are multiple ways
to handle <code>stmnt</code> productions. Depending on the particular input that is
provided it could 
either be reduced to a <code>stmt</code> or the parser could continue to consume input
by processing an <code>ELSE</code> token, eventually resulting in the recognition of
<code>IF '(' VAR ')' stmt ELSE stmt</code> as a <code>stmt</code>. 
<p>
There is little we can do but resorting to <code>%expect</code> to handle the dangling
else problem. The default handling is what most people intuitively expect and
so in this case using <code>%expect 1</code> is an easy way to prevent <strong>bisonc++</strong> from
reporting a shift/reduce conflict. But shift/reduce conflicts are most often
solved by specifying disambiguating rules specifying priorities or
associations, usually in the context of arithmetic expressions, as discussed
in the next sections.
<p>
However, shift-reduce conflicts can also be observed in grammars where a state
contains items that could be reduced to a certain non-terminal and items in
which a shift is possible in an item of a production rule of a completely
different non-terminal. Here is an example of such a grammar:
    <pre>
    %token  ID 
    %left  '-'
    %left  '*'
    %right UNARY
    
    %%
    
    expr:
        expr '-' term
    | 
        term
    ;
    
    term:
        term '*' factor
    | 
        factor
    ;
    
    factor:
       '-' expr %prec UNARY
    | 
        ID
    ;
</pre>

  Why these grammars show shift reduce conflicts and how these are solved is
discussed in the next section.
<p>
<a name="l113"></a>
<h2>7.2: Operator Precedence</h2>
Shift/reduce conflicts are frequently encountered in grammars specifying rules
of arithmetic expressions. Here shifting is not always the preferred
resolution; the <strong>bisonc++</strong> directives for operator precedence allow you to specify
when to shift and when to reduce. How and when to do so is discussed next.
<p>
<a name="l114"></a>
<h3>7.2.1: When Precedence is Needed</h3>
    Consider the following ambiguous grammar fragment (ambiguous because the input
`<code>1 - 2 * 3</code>' can be parsed in two different ways):
        <pre>

    expr:     
        expr '-' expr
    |
        expr '*' expr
    | 
        expr '&lt;' expr
    | 
        '(' expr ')'
    ...
    ;
        
</pre>

    Suppose the parser has seen the tokens `<code>1</code>', `<code>-'</code> and `<code>2</code>';
should it reduce them via the rule for the addition operator? It depends on
the next token. Of course, if the next token is `)', we must reduce;
shifting is invalid because no single rule can reduce the token sequence `<code>-
2</code> )' or anything starting with that. But if the next token is `<code>*</code>'
or `<code>&lt;</code>', we have a choice: either shifting or reduction would allow the
parse to complete, but with different results.
<p>
To decide which one <strong>bisonc++</strong> should do, we must consider the results. If
the next operator token <code>op</code> is shifted, then it must be reduced first in
order to permit another opportunity to reduce the sum. The result is (in
effect) `<code>1 - (2 op 3)</code>'. On the other hand, if the subtraction is reduced
before shifting <code>op</code>, the result is `<code>(1 - 2) op 3</code>'. Clearly, then, the
choice of shift or reduce should depend on the relative precedence of the
operators `<code>-</code>' and <code>op</code>: `<code>*</code>' should be shifted first, but not
`<code>&lt;</code>'.
<p>
What about input such as `<code>1 - 2 - 5</code>'; should this be `<code>(1 - 2) - 5</code>' or
should it be `<code>1 - (2 - 5)</code>'? For most operators we prefer the former, which
is called <em>left association</em>. The latter alternative, <em>right association</em>,
is desirable for, e.g., assignment operators. The choice of left or right
association is a matter of whether the parser chooses to shift or reduce when
the stack contains `<code>1 - 2</code>' and the look-ahead token is `<code>-</code>': shifting
results in right-associativity.
<p>
<a name="l115"></a>
<h3>7.2.2: Specifying Operator Precedence</h3>
    <strong>Bisonc++</strong> allows you to specify these choices with the operator precedence
directives <code>%left</code> and <code>%right</code>. Each such directive contains a list of
tokens, which are operators whose precedence and associativity is being
declared. The <code>%left</code> directive makes all those operators left-associative
and the <code>%right</code> directive makes them right-associative. A third alternative
is <code>%nonassoc</code>, which declares that it is a syntax error to find the same
operator twice `in a row'. Actually, <code>%nonassoc</code> is not currently (0.98.004)
punished that way by <strong>bisonc++</strong>. Instead, <code>%nonassoc</code> and <code>%left</code> are
handled identically.
<p>
The relative precedence of different operators is controlled by the order in
which they are declared. The first <code>%left</code> or <code>%right</code> directive in the
file declares the operators whose precedence is lowest, the next such
directive declares the operators whose precedence is a little higher, and so
on.
<p>
<a name="l116"></a>
<h3>7.2.3: Precedence Examples</h3>
    In our example, we would want the following declarations:
        <pre>

    %left '&lt;'
    %left '-'
    %left '*'
        
</pre>

    In a more complete example, which supports other operators as well, we
would declare them in groups of equal precedence. For example, '<code>+</code>' is
declared with '<code>-</code>':
        <pre>

    %left '&lt;' '&gt;' '=' NE LE GE
    %left '+' '-'
    %left '*' '/'
        
</pre>

    (Here <code>NE</code> and so on stand for the operators for `not equal' and so
on. We assume that these tokens are more than one character long and therefore
are represented by names, not character literals.)
<p>
<a name="l117"></a>
<h3>7.2.4: How Precedence Works</h3>
    The first effect of the precedence directives is to assign precedence levels
to the terminal symbols declared. The second effect is to assign precedence
levels to certain rules: each rule gets its precedence from the last terminal
symbol mentioned in the components. (You can also specify explicitly the
precedence of a rule. See section <a href="bisonc++07.html#CONDEP">7.3</a>).
<p>
Finally, the resolution of conflicts works by comparing the precedence of the
rule being considered with that of the look-ahead token. If the token's
precedence is higher, the choice is to shift. If the rule's precedence is
higher, the choice is to reduce. If they have equal precedence, the choice is
made based on the associativity of that precedence level. The verbose output
file made by `<code>-V</code>' (see section <a href="bisonc++09.html#INVOKING">9</a>) shows how each conflict was
resolved.
<p>
Not all rules and not all tokens have precedence. If either the rule or the
look-ahead token has no precedence, then the default is to shift.
<p>
<a name="l118"></a>
<h3>7.2.5: Rule precedence</h3>
    Consider the following (somewhat peculiar) grammar:
        <pre>
    %token  ID 
    %left  '-'
    %left  '*'
    %right UNARY
    
    %%
    
    expr:
        expr '-' term
    | 
        term
    ;
    
    term:
        term '*' factor
    | 
        factor
    ;
    
    factor:
       '-' expr %prec UNARY
    | 
        ID
    ;
</pre>

<p>
Even though operator precedence and association rules are used the grammar
still displays a shift/reduce conflict. One of the grammar's states consists
of the following two items:
        <pre>

    0: expr -&gt; term  .   
    1: term -&gt; term  . '*' factor
        
</pre>

 and <strong>bisonc++</strong> reduces to item 0, dropping item 1 rather than shifting a <code>'*'</code> and
proceeding with item 0. 
<p>
When considering states where shift/reduce conflicts are encountered the
`shiftable' items of these states shift when encountering terminal tokens that
are also in the follow sets of the reducible items of these states. In the
above example item 1 shifts when <code>'*'</code> is encountered, but <code>'*'</code> is also
an element of the set of look-ahead tokens of item 0. <strong>Bisonc++</strong> must now decide what
to do. In cases we've seen earlier <strong>bisonc++</strong> could make the decision because the
reducible item itself had a well known precedence. The precedence of a
reducible item is defined as the precedence of the left-hand side
non-terminal of the production rule to which the reducible item belongs. Item
0 in the above example is an item of the rule <code>expr -&gt; term</code>. 
<p>
The precedence of a production rule is defined as follows:
    <ul>
    <li> If <code>%prec</code> is used then the precedence of the production rule is
equal to the precedence of the terminal that is specified with the <code>%prec</code>
directive;
    <li> If <code>%prec</code> is not used then the production rule's precedence is
equal to the precedence of the first terminal token that is used in the
production rule;
    <li> In all other cases the production rule's precedence is set to the
maximum possible precedence.
    </ul>
<p>
Since <code>expr -&gt; term</code> does not contain a terminal token and does not use
<code>%prec</code>, its precedence is the maximum possible precedence. Consequently in
the above state the shift/reduce conflict is solved by <em>reducing</em> rather
than shifting. 
<p>
Some final remark as to why the above grammar is peculiar. It is peculiar as
it combines precedence and association specifying directives with auxiliary
non-terminals that may be useful conceptually (or when implementing an
expression parser `by hand') but which are not required when defining grammars
for <strong>bisonc++</strong>. The following grammar does not use <code>term</code> and <code>factor</code> but
recognizes the same grammar as the above `peculiar' grammar without reporting
any shift/reduce conflict:
        <pre>
    %token  ID 
    %left  '-'
    %left  '*'
    %right UNARY
    
    %%
    
    expr:
        expr '-' expr
    |
        expr '*' expr
    | 
       '-' expr %prec UNARY
    | 
        ID
    ;




</pre>

<p>
<a name="CONDEP"></a><a name="l119"></a>
<h2>7.3: Context-Dependent Precedence</h2>
Often the precedence of an operator depends on the context. This sounds
outlandish at first, but it is really very common. For example, a minus sign
typically has a very high precedence as a unary operator, and a somewhat lower
precedence (lower than multiplication) as a binary operator.
<p>
The <strong>bisonc++</strong> precedence directives, %left, %right and %nonassoc, can only be used
once for a given token; so a token has only one precedence declared in this
way. For context-dependent precedence, you need to use an additional
mechanism: the %prec modifier for rules.
<p>
The %prec modifier declares the precedence of a particular rule by specifying
a terminal symbol whose precedence should be used for that rule. It's not
necessary for that symbol to appear otherwise in the rule. The modifier's
syntax is:
    <pre>
%prec terminal-symbol
</pre>

<p>
and it is written after the components of the rule. Its effect is to assign
the rule the precedence of terminal-symbol, overriding the precedence that
would be deduced for it in the ordinary way. The altered rule precedence then
affects how conflicts involving that rule are resolved (see section Operator
Precedence).
<p>
Here is how %prec solves the problem of unary minus. First, declare a
precedence for a fictitious terminal symbol named UMINUS. There are no tokens
of this type, but the symbol serves to stand for its precedence:
    <pre>

    ...
    %left '+' '-'
    %left '*'
    %left UMINUS

</pre>

<p>
Now the precedence of UMINUS can be used in specific rules:
    <pre>
 
    exp:
        ...
        | exp '-' exp
        ...
        | '-' exp %prec UMINUS

</pre>

<p>
<a name="l120"></a>
<h2>7.4: Reduce/Reduce Conflicts</h2>
A <em>reduce/reduce conflict</em> occurs if there are two or more rules that apply
to the same sequence of input. This usually indicates a serious error in the
grammar.
<p>
For example, here is an erroneous attempt to define a sequence of zero or more
word groupings:
        <pre>

    %stype char *
    %token WORD

    %%

    sequence: 
        // empty 
        { 
            cout &lt;&lt; "empty sequence\n"; 
        }
    | 
        maybeword
    | 
        sequence WORD
        { 
            cout &lt;&lt; "added word " &lt;&lt; $2 &lt;&lt; endl;
        }
    ;

    maybeword: 
        // empty 
        { 
            cout &lt;&lt; "empty maybeword\n"; 
        }
    | 
        WORD
        { 
            cout &lt;&lt; "single word " &lt;&lt; $1 &lt;&lt; endl;
        }
    ;

</pre>

<p>
The error is an ambiguity: there is more than one way to parse a single
word into a sequence. It could be reduced to a maybeword and then into a
sequence via the second rule. Alternatively, nothing-at-all could be reduced
into a sequence via the first rule, and this could be combined with the word
using the third rule for sequence.
<p>
There is also more than one way to reduce nothing-at-all into a sequence. This
can be done directly via the first rule, or indirectly via maybeword and then
the second rule.
<p>
You might think that this is a distinction without a difference, because it
does not change whether any particular input is valid or not. But it does
affect which actions are run. One parsing order runs the second rule's action;
the other runs the first rule's action and the third rule's action. In this
example, the output of the program changes.
<p>
<strong>Bisonc++</strong> resolves a reduce/reduce conflict by choosing to use the rule that appears
first in the grammar, but it is very risky to rely on this. Every
reduce/reduce conflict must be studied and usually eliminated. Here is the
proper way to define sequence:
    <pre>

    sequence: 
        // empty 
        { printf ("empty sequence\n"); }
    | sequence word
        { printf ("added word %s\n", $2); }
    ;
    
</pre>

<p>
Here is another common error that yields a reduce/reduce conflict:
    <pre>
 
    sequence: 
        // empty 
        | sequence words
        | sequence redirects
    ;

    words:    
        // empty 
        | words word
    ;

    redirects:
        // empty
        | redirects redirect
    ;
    
</pre>

<p>
The intention here is to define a sequence which can contain either word or
redirect groupings. The individual definitions of sequence, words and
redirects are error-free, but the three together make a subtle ambiguity: even
an empty input can be parsed in infinitely many ways!
<p>
Consider: nothing-at-all could be a words. Or it could be two words in a row,
or three, or any number. It could equally well be a redirects, or two, or any
number. Or it could be a words followed by three redirects and another
words. And so on.
<p>
Here are two ways to correct these rules. First, to make it a single level of
sequence:
    <pre>

    sequence: 
        // empty
        | sequence word
        | sequence redirect
    ;
    
</pre>

<p>
Second, to prevent either a words or a redirects from being empty:
    <pre>

    sequence: 
        // empty
        | sequence words
        | sequence redirects
    ;

    words:    
        word
        | words word
    ;

    redirects:
        redirect
        | redirects redirect
    ;
    
</pre>

<p>
<a name="MYSTERIOUS"></a><a name="l121"></a>
<h2>7.5: Mysterious Reduce/Reduce Conflicts</h2>
Sometimes reduce/reduce conflicts occur that are puzzling at first sight. Here
is an example:
        <pre>

    %token ID
    
    %%
    def:    
        param_spec return_spec ','
    ;

    param_spec:
        type
    |    
        name_list ':' type
    ;

    return_spec:
        type
    |
        name ':' type
    ;

    type:
        ID
    ;

    name:
        ID
    ;

    name_list:
        name
    |
        name ',' name_list
    ;
        
</pre>
 
    It would seem that this grammar can be parsed with only a single
look-ahead token: when a param_spec is being read, an <code>ID</code> is a <code>name</code> if
a comma or colon follows, or a <code>type</code> if another <code>ID</code> follows. In other
words, this grammar is LR(1).
<p>
However, <strong>bisonc++</strong>, like most parser generators, cannot actually handle all LR(1)
grammars. In this grammar two contexts, one after an <code>ID</code> at the beginning
of a <code>param_spec</code> and another one at the beginning of a <code>return_spec</code>, are
similar enough for <strong>bisonc++</strong> to assume that they are identical. They appear similar
because the same set of rules would be active--the rule for reducing to a name
and that for reducing to a type. <strong>Bisonc++</strong> is unable to determine at that stage of
processing that the rules would require different look-ahead tokens in the two
contexts, so it makes a single parser state for them both. Combining the two
contexts causes a conflict later. In parser terminology, this occurrence means
that the grammar is not LALR(1).
<p>
In general, it is better to fix deficiencies than to document them. But this
particular deficiency is intrinsically hard to fix; parser generators that can
handle LR(1) grammars are hard to write and tend to produce parsers that are
very large. In practice, <strong>bisonc++</strong> is more useful the way it's currently operating.
<p>
When the problem arises, you can often fix it by identifying the two parser
states that are being confused, and adding something to make them look
distinct. In the above example, adding one rule to <code>return_spec</code> as follows
makes the problem go away:
        <pre>

    %token BOGUS
    ...
    %%
    ...
    return_spec:
        type
    |    
        name ':' type
    |    
        ID BOGUS        // This rule is never used. 
    ;
        
</pre>
 
    This corrects the problem because it introduces the possibility of an
additional active rule in the context after the <code>ID</code> at the beginning of
<code>return_spec</code>. This rule is not active in the corresponding context in a
<code>param_spec</code>, so the two contexts receive distinct parser states. As long as
the token <code>BOGUS</code> is never generated by the parser's member function
<code>lex()</code>, the added rule cannot alter the way actual input is parsed.
<p>
In this particular example, there is another way to solve the problem: rewrite
the rule for <code>return_spec</code> to use <code>ID</code> directly instead of via name. This
also causes the two confusing contexts to have different sets of active rules,
because the one for <code>return_spec</code> activates the altered rule for
<code>return_spec</code> rather than the one for name.
        <pre>

    param_spec:
        type
    |    
        name_list ':' type
    ;

    return_spec:
        type
    |    
        ID ':' type
    ;
        
</pre>

<p>
<hr>
<ul>
    <li> <a href="bisonc++.html">Table of Contents</a>
    <li> <a href="bisonc++06.html">Previous Chapter</a>
    <li> <a href="bisonc++08.html">Next Chapter</a>
</ul>
<hr>
</body>
</html>
